{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crucial-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1020303\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"../../../chromedriver\")\n",
    "airlines = pd.read_csv(\"../data/airline_links_tripadvisor.csv\")\n",
    "airlines = airlines.loc[airlines[\"review_count\"] < 20000]\n",
    "print(airlines[\"review_count\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_element_click(\n",
    "    driver,\n",
    "    by,\n",
    "    expression,\n",
    "):\n",
    "    \"\"\"Find the element and click then  handle all type of exception during click\n",
    "    Args:\n",
    "        driver (selenium.driver): Selenium driver\n",
    "        by (selenium.webdriver.common.by): Type of selector\n",
    "            (By.XPATH, By.CSS_SELECTOR ...)\n",
    "        expression (str): Selector expression to the element to click on\n",
    "    Returns:\n",
    "        bool: True if successfully clicked on the element\n",
    "    \"\"\"\n",
    "    end_time = time.time() + 8\n",
    "    while True:\n",
    "        try:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            web_element = driver.find_element(by=by, value=expression)\n",
    "            web_element.click()\n",
    "            return True\n",
    "        except:\n",
    "            if time.time() > end_time:\n",
    "                break\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AEGEAN\n",
      "  2%|‚ñè         | 17/958 [00:25<22:43,  1.45s/it]"
     ]
    }
   ],
   "source": [
    "#Go through all the pages of reviews\n",
    "i = 0\n",
    "airline_name = []\n",
    "reviews = []\n",
    "dates = []\n",
    "scores = []\n",
    "tags = []\n",
    "\n",
    "for airline in airlines[\"airlines\"]:\n",
    "    if airlines.loc[airlines['airlines'] == airline][\"review_count\"].values[0] < 1000:\n",
    "        continue\n",
    "    print(airline)\n",
    "    #Get reviews from airline\n",
    "    url = \"https://www.tripadvisor.com\" + airlines.loc[airlines['airlines'] == airline][\"links\"].values[0] + \"#REVIEWS\"\n",
    "    [prefix_url, suffix_url] = url.split(\"Reviews\")\n",
    "    driver.get(url)\n",
    "    #Scroll down page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    page = BeautifulSoup(driver.page_source)\n",
    "    try:\n",
    "        total_pages = int(page.find(\"div\", {\"class\": \"pageNumbers\"}).find_all(\"a\")[-1].text)\n",
    "    except:\n",
    "        total_pages = 1\n",
    "    for i in tqdm(range(total_pages)):\n",
    "        driver.get(url)\n",
    "        #driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        page = BeautifulSoup(driver.page_source)\n",
    "\n",
    "        #Review text\n",
    "        for review in page.find_all(\"q\", {\"class\": \"IRsGHoPm\"}):\n",
    "            reviews.append(review.text)\n",
    "            airline_name.append(airline)\n",
    "        \n",
    "        #Review date\n",
    "        for date in page.find_all(\"span\", {\"class\": \"_34Xs-BQm\"}):\n",
    "            dates.append(date.text)\n",
    "\n",
    "        #Review scores\n",
    "        for score in page.find_all(\"div\", {\"class\": \"nf9vGX55\"}):\n",
    "            scores.append(int(score.find(\"span\").get(\"class\")[1][7]))\n",
    "\n",
    "        #Trip information\n",
    "        for tag in page.find_all(\"div\", {\"class\": \"hpZJCN7D\"}):\n",
    "            tags.append([stag.text for stag in tag.find_all(\"div\", {\"class\": \"_3tp-5a1G\"})])\n",
    "        \n",
    "        if total_pages > 1:\n",
    "            #result = _find_element_click(driver, webdriver.common.by.By.XPATH, \".//a[@class='ui_button nav next primary ']\")\n",
    "            url = prefix_url + \"Reviews-or\" + str((i + 1)*5) + suffix_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame({\"airline_name\": airline_name,\"reviews\": reviews, \"scores\": scores, \"tags\": tags})\n",
    "reviews.to_csv(\"../data/trip_advisor_reviews.csv\", sep = \",\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}